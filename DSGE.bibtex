Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{Betancourt2017,
abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important.
In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
archivePrefix = {arXiv},
arxivId = {1701.02434},
author = {Betancourt, Michael},
booktitle = {arXiv},
eprint = {1701.02434},
title = {{A Conceptual Introduction to Hamiltonian Monte Carlo}},
year = {2017}
}

@article{Hoffman2014,
abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size e and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS performs at least as efficiently as (and sometimes more efficiently than) a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter e on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all, making it suitable for applications such as BUGS-style automatic inference engines that require efficient "turnkey" samplers. {\textcopyright} 2014 Matthew D. Hoffman and Andrew Gelman.},
archivePrefix = {arXiv},
arxivId = {1111.4246},
author = {Hoffman, Matthew D. and Gelman, Andrew},
eprint = {1111.4246},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Adaptive Monte Carlo,Bayesian inference,Dual averaging,Hamiltonian Monte Carlo,Markov chain Monte Carlo},
title = {{The no-U-turn sampler: Adaptively setting path lengths in Hamiltonian Monte Carlo}},
year = {2014}
}
@article{Anderson1985,
abstract = {This paper presents a failsafe method for analyzing any linear perfect foresight model. It describes a procedure which either computes the reduced-form solution or indicates why the model has no reduced form. {\textcopyright} 1985.},
author = {Anderson, Gary and Moore, George},
doi = {10.1016/0165-1765(85)90211-3},
issn = {01651765},
journal = {Economics Letters},
title = {{A linear algebraic procedure for solving linear perfect foresight models}},
year = {1985}
}
@incollection{Neal2011,
archivePrefix = {arXiv},
arxivId = {1206.1901},
author = {Neal, Radford M.},
booktitle = {Handbook of Markov Chain Monte Carlo},
doi = {10.1201/b10905-6},
eprint = {1206.1901},
isbn = {9781420079425},
title = {{MCMC using hamiltonian dynamics}},
year = {2011}
}
@book{Canova2011,
abstract = {The last twenty years have witnessed tremendous advances in the mathematical, statistical, and computational tools available to applied macroeconomists. This rapidly evolving field has redefined how researchers test models and validate theories. Yet until now there has been no textbook that unites the latest methods and bridges the divide between theoretical and applied work.Fabio Canova brings together dynamic equilibrium theory, data analysis, and advanced econometric and computational methods to provide the first comprehensive set of techniques for use by academic economists as well as professional macroeconomists in banking and finance, industry, and government. This graduate-level textbook is for readers knowledgeable in modern macroeconomic theory, econometrics, and computational programming using RATS, MATLAB, or Gauss. Inevitably a modern treatment of such a complex topic requires a quantitative perspective, a solid dynamic theory background, and the development of empirical and numerical methods--which is where Canova's book differs from typical graduate textbooks in macroeconomics and econometrics. Rather than list a series of estimators and their properties, Canova starts from a class of DSGE models, finds an approximate linear representation for the decision rules, and describes methods needed to estimate their parameters, examining their fit to the data. The book is complete with numerous examples and exercises.Today's economic analysts need a strong foundation in both theory and application.Methods for Applied Macroeconomic Researchoffers the essential tools for the next generation of macroeconomists. {\textcopyright} 2007 by Princeton University Press. All Rights Reserved.},
author = {Canova, Fabio},
booktitle = {Methods for Applied Macroeconomic Research},
doi = {10.2307/j.ctvcm4hrv},
isbn = {0691115044},
title = {{Methods for applied macroeconomic research}},
year = {2011}
}
@book{Gelman2014,
abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors—all leaders in the statistics community—introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book's web page.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Gelman, Andrew and Carlin, John B B and Stern, Hal S S and Rubin, Donald B B},
booktitle = {Book},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
isbn = {9781439840955},
issn = {1467-9280},
pmid = {25052830},
title = {{Bayesian Data Analysis, Third Edition (Texts in Statistical Science)}},
year = {2014}
}
@article{Carvalho2015,
author = {de Carvalho, Carlos Viana and Vilela, Andr{\'{e}} D.},
doi = {10.12660/bre.v35n22015.57569},
issn = {1980-2447},
journal = {Brazilian Review of Econometrics},
title = {{What lf Brazil Hadn't Floated the Real in 1999?}},
year = {2015}
}
@book{Gali2009,
abstract = {The New Keynesian framework has emerged as the workhorse for the analysis of monetary policy and its implications for inflation, economic fluctuations, and welfare. It is the backbone of the new generation of medium-scale models under development at major central banks and international policy institutions, and provides the theoretical underpinnings of the inflation stability-oriented strategies adopted by most central banks throughout the industrialized world. This graduate-level textbook provides an introduction to the New Keynesian framework and its applications to monetary policy.Using a canonical version of the New Keynesian model as a reference framework, Jordi Gal explores issues pertaining to the design of monetary policy, including the determination of the optimal monetary policy and the desirability of simple policy rules. He analyzes several extensions of the baseline model, allowing for cost-push shocks, nominal wage rigidities, and open economy factors. In each case, the implications for monetary policy are addressed, with a special emphasis on the desirability of inflation targeting policies.The most up-to-date and accessible introduction to the New Keynesian framework availableUses a single benchmark model throughoutConcise and easy to useIncludes exercisesAn ideal resource for graduate students, researchers, and market analysts. {\textcopyright} 2008 by Princeton University Press. All Rights Reserved.},
author = {Gal{\'{i}}, Jordi},
booktitle = {Monetary Policy, Inflation, and the Business Cycle: An Introduction to the New Keynesian Framework},
doi = {10.1111/j.1475-4932.2009.00606.x},
isbn = {9780691133164},
issn = {00130249},
title = {{Monetary policy, inflation, and the business cycle: An introduction to the new Keynesian framework}},
year = {2009}
}
@article{Blanchard1980,
abstract = {No abstract is available for this item.},
author = {Blanchard, Olivier Jean and Kahn, Charles M.},
doi = {10.2307/1912186},
issn = {00129682},
journal = {Econometrica},
title = {{The Solution of Linear Difference Models under Rational Expectations}},
year = {1980}
}
@book{Magnus2019,
  title={Matrix differential calculus with applications in statistics and econometrics},
  author={Magnus, Jan R and Neudecker, Heinz},
  year={2019},
  publisher={John Wiley \& Sons}
}

@inproceedings{Strathmann2015a,
abstract = {We propose Kernel Hamiltonian Monte Carlo (KMC), a gradient-free adaptive MCMC algorithm based on Hamiltonian Monte Carlo (HMC). On target densities where classical HMC is not an option due to intractable gradients, KMC adaptively learns the target's gradient structure by fitting an exponential family model in a Reproducing Kernel Hilbert Space. Computational costs are reduced by two novel efficient approximations to this gradient. While being asymptotically exact, KMC mimics HMC in terms of sampling efficiency, and offers substantial mixing improvements over state-of-the-art gradient free samplers. We support our claims with experimental studies on both toy and real-world applications, including Approximate Bayesian Computation and exact-approximate MCMC.},
archivePrefix = {arXiv},
arxivId = {1506.02564},
author = {Strathmann, Heiko and Sejdinovic, Dino and Livingstone, Samuel and Szabo, Zoltan and Gretton, Arthur},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1506.02564},
issn = {10495258},
title = {{Gradient-free Hamiltonian Monte Carlo with efficient Kernel exponential families}},
year = {2015}
}
@incollection{Keesman2011,
author = {Keesman, Karel J.},
booktitle = {Advanced Textbooks in Control and Signal Processing},
doi = {10.1007/978-0-85729-522-4},
issn = {25103814},
title = {{System identification: An introduction}},
year = {2011}
}
@article{Iskrev2010,
abstract = {The issue of identification arises whenever structural models are estimated. Lack of identification means that the empirical implications of some model parameters are either undetectable or indistinguishable from the implications of other parameters. Therefore, identifiability must be verified prior to estimation. This paper provides a simple method for conducting local identification analysis in linearized DSGE models, estimated in both full and limited information settings. In addition to establishing which parameters are locally identified and which are not, researchers can determine whether the identification failures are due to data limitations, such as lack of observations for some variables, or whether they are intrinsic to the structure of the model. The methodology is illustrated using a medium-scale DSGE model. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Iskrev, Nikolay},
doi = {10.1016/j.jmoneco.2009.12.007},
issn = {03043932},
journal = {Journal of Monetary Economics},
keywords = {DSGE models,Identification},
title = {{Local identification in DSGE models}},
year = {2010}
}
@article{Sims2002,
abstract = {We describe methods for solving general linear rational expectations models in continuous or discrete timing with or without exogenous variables. The methods are based on matrix eigenvalue decompositions. {\textcopyright} 2002 Kluwer Academic Publishers.},
author = {Sims, Christopher A.},
doi = {10.1023/A:1020517101123},
issn = {09277099},
journal = {Computational Economics},
keywords = {QZ decomposition,generalized Schur decomposition,rational expectations},
title = {{Solving Linear Rational Expectations Models}},
year = {2002}
}

@techreport{Villaverde2020,
 title = "Estimating DSGE Models: Recent Advances and Future Challenges",
 author = "Fernández-Villaverde, Jesús and Guerrón-Quintana, Pablo A",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "27715",
 year = "2020",
 month = "August",
 doi = {10.3386/w27715},
 URL = "http://www.nber.org/papers/w27715",
 abstract = {We review the current state of the estimation of DSGE models. After introducing a general framework for dealing with DSGE models, the state-space representation, we discuss how to evaluate moments or the likelihood function implied by such a structure. We discuss, in varying degrees of detail, recent advances in the field, such as the tempered particle filter, approximated Bayesian computation, the Hamiltonian Monte Carlo, variational inference, and machine learning, methods that show much promise, but that have not been fully explored yet by the DSGE community. We conclude by outlining three future challenges for this line of research.},
}
@book{Lomba2012,
  title={Estimation of dynamic econometric models with errors in variables},
  author={Lomba, Jaime Terceiro},
  volume={339},
  year={2012},
  publisher={Springer Science \& Business Media}
}
